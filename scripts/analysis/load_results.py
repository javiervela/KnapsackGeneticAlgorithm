"""
This script loads results from JSON files generated by the genetic algorithm experiments, aggregates the data, and saves it into a parquet file for further analysis.
"""

import os
import json

import pandas as pd


BASE_RESULTS_DIR = "results/experiment_all/"

PROBLEM_INDEXES = list(range(7))
EXECUTIONS_N = list(range(31))
POPULATION_SIZE = 10
FUNCTION_EVALUATIONS = [-1, 1000, 10000]
CROSSOVER_PROBABILITIES = [0.1, 0.3, 0.5, 0.7, 0.9, 1]
MUTATION_PROBABILITIES = [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]

data = []

for function_evaluations in FUNCTION_EVALUATIONS:
    for problem_index in PROBLEM_INDEXES:
        for crossover_probability in CROSSOVER_PROBABILITIES:
            for mutation_probability in MUTATION_PROBABILITIES:
                for execution_i in EXECUTIONS_N:
                    results_file = f"{BASE_RESULTS_DIR}/function_evaluations_{function_evaluations}/problem_{problem_index}/crossover_{crossover_probability}/mutation_{mutation_probability}/results_{execution_i}.json"

                    if os.path.exists(results_file):
                        with open(results_file, "r", encoding="utf-8") as f:
                            result_data = json.load(f)
                            result_data["problemIndex"] = problem_index
                            result_data["crossoverProbability"] = crossover_probability
                            result_data["mutationProbability"] = mutation_probability
                            result_data["execution"] = execution_i
                            result_data["functionEvaluations"] = function_evaluations
                            data.append(result_data)

df = pd.json_normalize(data)

# Save into parquet
df.to_parquet("./data/results.parquet", index=False)
